## Model Diagnostics

### Convergence

```{r render-model-jitter, results = "asis", eval = ifelse(file.exists(file.path(dirname(model_location), "base_jitter_0.05", "model-results-jitter.md")), FALSE, FALSE)}
sa4ss::read_child(
  file.path(
    dirname(model_location),
    "base_jitter_0.05",
    "model-results-jitter.md"
  )
)
```

Model convergence was evaluated by starting the minimization process from dispersed values of the maximum likelihood estimates to determine if the model found a better minimum. Starting parameters were jittered using the jitter function built into Stock Synthesis, using a jitter input of 0.05. This was repeated 100 times with 16 out of 100 runs returning to the base model likelihood. A better, lower negative log-likelihood, model fit was not found. Through the jittering and the likelihood profiles, we are confident that the base model, as presented, represents the best fit to the data given the assumptions made. There were no difficulties in inverting the Hessian to obtain estimates of variability.

During the process of jittering the starting parameter values it was noted that often one or more selectivity parameters were estimated on their bounds. The estimated measures of uncertainty for `r xfun::numbers_to_words(NROW(parameters_bad))` parameters, primarily selectivity parameters, were excessively large with standard deviations in the hundreds, if not thousands, suggesting that they were poorly informed. We chose to leave their parameterization as is but we do show a sensitivity where all of these parameters were fixed at their estimated values to characterize changes the amount of uncertainty in derived quantities when they were not estimated compared to the base model where they were estimated (see Section \@ref(sensitivity-analyses) and Figure \@ref(fig:sensitivity-3-compare4)).


### Sensitivity Analyses

Several sensitivity analyses were conducted to examine the relative influence of specific changes to data inputs and structural model assumptions to further address uncertainty associated with the base model estimates and derived management quantities. The first group of sensitivity analyses include changes to the data or model assumptions that should be addressed in the next benchmark assessment but led to almost no changes compared to the current base model. The second group of sensitivity analyses includes models with changed assumptions that did lead to differences compared to the base model. The third group of sensitivity analyses mainly includes sensitivities required by the \gls{tor}.

The environmental index used in the base model is the result of a dynamic factor analysis implemented using a multivariate autoregressive state-space model, the same model that was used for the 2019 assessment [@haltuch_status_2019b]. In the 2021 analysis, the dynamic factor analysis showed some instability and a similar Bayesian analysis was investigated that proved to be more robust. The Bayesian output was also updated this year and included as a sensitivity. The results are largely the same (Figures \@ref(fig:sensitivity-1-compare2)--\@ref(fig:sensitivity-1-compare4)), as expected.

Estimates of uncertainty for some selectivity parameters in the base model were high. It was hoped that fixing the parameters that control the difference in male and female selectivity for the trawl fleet and the \gls{s-tri} at age zero to zero rather than estimating them would decrease the high estimated uncertainty in other parameters but this was not the case. The uncertainties for the problematic parameters were still high but the resulting time series are the same (Figures \@ref(fig:sensitivity-1-compare2)--\@ref(fig:sensitivity-1-compare4)). Fixing these two selectivity parameters at zero is justified because one would not expect the selectivity of age-0 fish to be different between males and females and there are very few age-0 fish caught in the trawl fleet and the \gls{s-tri} to inform the differences between male and female selectivity at age zero even if there was one. We tried to estimate the two retention parameters that were fixed at their bounds in the bridging analysis to see if tuning the model facilitated estimating them. Both parameters still went to their bounds when estimated. The results from the run with the parameters estimated is nearly the same as the results from the base model but it is poor practice to use results from a model run with parameters on the bound because estimates variance can be suspect when a parameter is on the bound. Thus, we choose to keep them fixed in the base model.

Recent best practices suggest that we should not be constraining recruitment deviations in the main period to sum to zero. Estimated recruitment deviations for a given model can be seen as a sample from a theoretical distribution rather than a census. Thus, we would never expect a sample of a deviation vector to sum to zero so we turned the sum to zero constraint off as a sensitivity. Most of the differences between this model and the base model occur in the historical time period when there is little information about recruitment (Figures \@ref(fig:sensitivity-2-compare11)--\@ref(fig:sensitivity-2-compare4)), which is a reflection of the change in $R_0$ (Table \@ref(tab:sensitivity-ests-2)) rather than a change in specific estimates of recruitment. 

Estimating additional variance for the \gls{s-wcgbt} led to the model not fitting the most recent survey year nearly as well as the base model and thus the upward trend at the end of the time series became less pronounced (Figure \@ref(fig:sensitivity-2-compare13)). The estimates of spawning biomass were larger for this sensitivity than the base model because all of the large recruitment events, except for the most recent one, were estimated at higher values than what were estimated in the base model. This also led to increases in other quantities relevant to management (Table \@ref(tab:sensitivity-ests-2)) like yield at \gls{spr}.

Tuning the model using the harmonic-mean method versus the Francis method led to a significant change in the weight applied to the \gls{s-tri} ages. In the base model, Francis tuning led to larger weights for these data relative to the other data sets but the multiplier was capped at 1.0. With the harmonic-mean method, the multiplier was less than 0.1. As a result, the \gls{s-tri} index was fit better and the \gls{s-wcgbt} was fit less well compared to the base model. The estimated trajectories of spawning biomass are similar between the two models from the early 1980s going forward (Figure \@ref(fig:sensitivity-3-compare2)) but the harmonic-mean method led to a lower estimate of $R_0$ and smaller estimates of early recruitment compared to the base model.

Estimating a single $M$ instead of sex-specific $M$ resulted in a lower estimate ($M$ = 0.053 yr$^{-1}$) than estimates of either female or male $M$ from the base model (`r text_parameter(model, "NatM.+Fem", "%.3f")` yr$^{-1}$ and `r text_parameter(model, "NatM.+Mal", "%.3f")` yr$^{-1}$, respectively). This is the same result as the 2021 update assessment [@Kapur:2021:SSA]. The estimate of unfished spawning biomass, while within the uncertainty bounds of the current base model, was below the base model estimate. Estimating a single $M$ reduced the size of large recruitment events and suggested that the population was just barely above $B_{40\%}$ in 2021 (Figures \@ref(fig:sensitivity-3-compare2)--\@ref(fig:sensitivity-3-compare4)).

Fitting to the marginal rather than conditional ages for all years from the \gls{s-wcgbt} led to a higher estimate of $R_0$ compared to the base model (Table \@ref(tab:sensitivity-ests-3)), though still within the range of uncertainty characterized by the base model (Figure \@ref(fig:sensitivity-3-compare2)). This was the only sensitivity that led to estimates of the 2022 survey index for the \gls{s-wcgbt} within the input uncertainty.

Implementing asymptotic age-based selectivity for the \gls{s-wcgbt} reduced $R_0$ and also reduced the absolute size of large recruitment events (Figure \@ref(fig:sensitivity-3-compare2)). This model had a higher overall log-likelihood than the base model and did a poorer job of fitting the length compositions from that survey, particularly in the most recent years (Table \@ref(tab:sensitivity-ests-3)).

### Retrospective Analysis

A retrospective analysis was conducted by running the base model with
data removed for the past `r n_retro` years. All retrospective model runs fell within the uncertainty estimates from the base model (Table \@ref(tab:retro-ests)). There was limited evidence of a retrospective pattern in estimates of spawning biomass (Figure \@ref(fig:RetroSsb)) and stock status (Figure \@ref(fig:RetroFractionunfished)). The retrospective pattern in stock status is largely driven by the relative amount of data available to inform the estimates of some of the largest recruitment events observed for `r spp`.

### Historical Analysis

Estimates of the current spawning biomass (Figure \@ref(fig:historical-model-comparison-sb)) and fraction unfished (Figure \@ref(fig:historical-model-comparison-unfished)) were consistent with prior stock assessments, particularly from the 1980s forward, the period of time with good data for `r spp`. Estimates of recent spawning biomass are greater for this update and the 2019 update compared to the three previous models, all of which estimate a lower spawning biomass than what is currently estimated. These larger estimates of spawning biomass are primarily due to the large estimates of recruitment for the recent years in the recent models. Models ran prior the last benchmark assessment differ from more recent models that use a larger age group for the maximum age in the data bins. Estimates from this `r document_type` of fraction unfished align with estimates from recent models for years in the 1960s and older models for years in the 1980s, highlighting the uncertainty in the magnitude of the large recruitment event in the early 1960s. See Figure 83 in @haltuch_status_2019b for comparisons to older assessments of `r spp`, i.e., back to 2005.

### Likelihood Profiles

Likelihood profiles were conducted for sex-specific $M$, $h$, $R_0$. These likelihood profiles were conducted by fixing the parameter of interest at specific values and estimating the remaining parameters based on the fixed parameter value. The priors for all parameters, including the parameter being profiled, were included in every likelihood calculation. For example, including the prior on $M$ across the profiled values of $M$ provides information on the likelihood contribution of that prior as if it were estimated in the model. 

The profile over female $M$ suggested the negative log-likelihood was minimized at the same value estimated in the base base model,
`r text_parameter(model, "NatM.+Fem", "%.3f")` yr$^{-1}$ (Figure \@ref(fig:profile-female-natural-mortality-piner)). This minimization occurs at the crosshair of information present in the age versus recruitment data. Though, the differences in the negative log likelihood were less than two for a range of values between 0.06--0.09 yr$^{-1}$, similar to the 2019 benchmark assessment [@haltuch_status_2019b]. This is not a trivial parameter range and the assessment results vary considerably among these values in absolute scale (Figures \@ref(fig:profile-female-natural-mortality-compare1)--\@ref(fig:profile-female-natural-mortality-compare3)). Only the lowest investigated value, which was less than 0.06 yr$^{-1}$, led to the population going below the minimum stock size threshold (Figure \@ref(fig:profile-female-natural-mortality-compare3)). No investigated value included in the profile over male $M$ led to the population going below this threshold (Figure \@ref(fig:profile-male-natural-mortality-compare3)). Male $M$ was inherently smaller than female $M$ but the same range was used for both investigations rather than a relative range. The results would have probably been more similar if a relative range had been used.

Similar likelihoods were found for $R_0$ values between 9.4 and 10.4, values which led to a broad range of stock sizes (Figures \@ref(fig:profile-male-natural-mortality-piner)--\@ref(fig:profile-male-natural-mortality-compare3)). For all explored values, the population was estimated to currently be above the management target and only having been below the minimum size threshold in the late 1950s.

In the base model, $h$ is fixed at `r text_parameter(model, "steep", "%.1f")`, making it an important profile to evaluate as its uncertainty is not explicitly included in the results of the base model. In 2011, the maximum likelihood estimate for $h$ was 0.2, which implies zero surplus production and is biologically implausible. Profile results indicate essentially equal support in the data over a broad range of explored values (Figure \@ref(fig:profile-steepness-piner)). Most of the values included in the profile led to similar trajectories of spawning biomass (Figure \@ref(fig:profile-steepness-compare1)).
